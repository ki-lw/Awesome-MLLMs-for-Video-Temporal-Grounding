# Awesome-MLLMs-for-Video-Temporal-Grounding [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<h3 align="center">
🔥 <a href="https://arxiv.org/abs/xxxx">A Survey on Video Temporal Grounding with Multimodal Large Language Model</a>
</h3>

<div align="center">
    <p>
    作者信息
    </p>
    <p>
    <img src="resources/VTG-Task.png" alt="VTG Task" style="width:60%; max-width:1000px;"/>
    </p>
</div>

Video Temporal Grounding (VTG) focuses on locating and understanding temporal segments in untrimmed videos based on multimodal queries. Core tasks include **video moment retrieval**, **dense video captioning**, **video highlight detection**, and **temporally grounded video QA**, all requiring fine-grained temporal reasoning.

With the rise of Multimodal Large Language Models (MLLMs), VTG has seen transformative progress. These models bring powerful cross-modal alignment and semantic reasoning abilities, enabling flexible, generalizable solutions across VTG tasks.

This repository aims to serve as a curated reference point for researchers and practitioners interested in advancing the field of video temporal grounding through the lens of large multimodal models.



## News

## Table of Contents

- [Awesome-MLLMs-for-Video-Temporal-Grounding](#awesome-mllms-for-video-temporal-grounding)
  - [1️⃣ 🧠 Functional Roles of MLLMs in VTG-MLLMs](#funcitonal-roles)
    - [Facilitator](#facilitator)
    - [Executor](#executor)
  - [2️⃣ 🛠️ Training Paradigms of VTG-MLLMs](#training-paradigms)
    - [Pretraining](#pretraining)
    - [Fine-Tuning](#fine-tuning)
    - [Training-Free](#training-free)
  - [3️⃣ 🎞️ Video Feature Processing in VTG-MLLMs](#video-feature-processing)
    - [Visual Feature](#visual-feature)
      - [Compression](#Compression)
      - [Refinement](#Refinement)
    - [Temporal Feature](#temporal-feature)
      - [Explicit](#Explicit)
      - [Implicit](#Implicit)
  - [4️⃣ 📊 Tasks and Benchmarks](#tasks-and-benchmarks)
    - [Moment Retrieval](#moment-retrieval)
    - [Dense Captioning](#dense-captioning)
    - [Highlight Detection](#highlight-detection)
    - [Grounded VQA](#grounded-vqa)
  - [5️⃣ 📬 Contact](#contact)

---

## 🧠 Functional Roles of MLLMs in VTG-MLLMs

### Facilitator
.

### Executor
.

---

## 🛠️ Training Paradigms of VTG-MLLMs

### Pretraining  
.

### Fine-Tuning  
.

### Training-Free  
.

---

## 🎞️ Video Feature Processing in VTG-MLLMs

### Visual Feature

#### Compression  
.

#### Refinement  
.

### Temporal Feature

#### Explicit  
.

#### Implicit  
.

---

## 📊 Tasks and Benchmarks

### Moment Retrieval  
Identify the temporal segment corresponding to a textual query.

### Dense Captioning  
Generate multiple event descriptions with accurate temporal boundaries.

### Highlight Detection  
Select keyframes or short segments that best match a given textual query.

### Grounded VQA  
Answer time-sensitive questions based on video context, grounded in specific temporal evidence.

---

## Contact
If you find our survey is useful in your research, please consider giving us a star 🌟 and cite the following paper:

```bibtex
@article{
}
```

If you have any question about this project, do not hesitate to contact me liuwei030224@gmail.com.